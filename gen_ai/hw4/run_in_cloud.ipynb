{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Tqj2L2-zBk"
      },
      "source": [
        "**Before you start working on this notebook, please make sure that your implementation in train_qformer.py passes all unit tests provided.**\n",
        "\n",
        "First, create a folder in your drive, preferably named HW4_data or something of that sort. Then, for each of these three links, click 'Organize' or 'Add a shortcut to drive' in the top right and place them in your HW4_data folder:\n",
        "\n",
        "*   Cached GPT-2 text embeddings: https://drive.google.com/file/d/1dzgnRpI6ntdM9e9zDBFPsGpz09HfDgMp/view\n",
        "*   Pretrained DiT weights: https://drive.google.com/file/d/1ZKl5k4D6jfE1xe1T1NSlGal0SS-wxtOG/view\n",
        "*   Dense CIFAR text captions: https://drive.google.com/file/d/1SxJ4zjiuN1Qmqh7DavQbHpF-O2-f3NcU/view\n",
        "\n",
        "Also, upload the following to the same folder.\n",
        "\n",
        "*   ddpm.py\n",
        "*   dit.py\n",
        "*   train_qformer.py\n",
        "*   eval_qformer.py\n",
        "*   image_caption_data.py\n",
        "*   inference.yaml\n",
        "\n",
        "\n",
        "Connect to a A100, L4, or T4 GPU, configure the path below, mount your drive, and install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLulZTZ5-jbo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/<YOUR_FOLDER_NAME>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP7DsdSFBeOW"
      },
      "source": [
        "**Training your Q-Former**\n",
        "\n",
        "After adjusting paths (as needed) below, train your Q-Former for 50 epochs.\n",
        "\n",
        "NOTE: If your training gets killed after 5 or more epochs, the script should automatically save both your weights and optimizer states to your Google Drive every 5 epochs. \n",
        "Use --resume_optimizer_path, --resume_model_path, and --start_epoch to restart from an epoch that is a multiple of 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksUNKdtWBdmi"
      },
      "outputs": [],
      "source": [
        "!python train_qformer.py \\\n",
        "    --pretrained_model_path ./ddpm_dit_cifar_100_epochs.pth \\\n",
        "    --dense_captions_path \"./cifar10_dense_captions.jsonl\" \\\n",
        "    --epochs 50 \\\n",
        "    --batch_size 128 --lr 1e-4 \\\n",
        "    --save_model_path ./models/trained_qformer.pth \\\n",
        "    --gpt2_layer_index 12 --num_query_tokens 4 --device 0 --cfg 3.0 --data_dir ./data \\\n",
        "    --gpt2_cache_dir ./data --optimizer_ckpt_interval 5 \\\n",
        "    --cache_text_embeddings ./text_embeddings.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8uyaI-NFU3-"
      },
      "source": [
        "**Testing your Q-Former**\n",
        "\n",
        "Test your trained Q-Former by running the following command. You will need to update the inference.yaml file in order to generate all results required by the writeup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bHDhFrJFR9Z"
      },
      "outputs": [],
      "source": [
        "!python eval_qformer.py --config_yaml inference.yaml"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
